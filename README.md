<h1 align='center'>
🚂 RailScope 
</h1>
<h2 align='center'>
🚦 Real-Time Performance Analysis for UK National Rail 🛤️
</h2>

<h2> 📝 Project description: </h2>

The RTPPM API provides real-time data on the Public Performance Measure (PPM), including metrics such as on-time trains, late trains, canceled/very late trains, and an indicator of overall performance. The data from this API will be transformed and processed for non-technical users.

The RTPPM API data is expected to arrive every 60 seconds

The dashboard will display key performance indicators such as on-time percentage, cancellations, and delays.

The dashboard will be designed for use by both operations managers and other stakeholders who need to monitor the performance of the National Rail system, as well as the general public. By making the dashboard publicly available, anyone can monitor the performance of the National Rail system without having to study the technical aspects of the underlying APIs.


<h2> 🛠️ Pre requisites: </h2>

<h3> 📡 Network Rail Account </h3>
<hr>
First, register for an account by visiting https://publicdatafeeds.networkrail.co.uk/. 
<br> 

You will receive a confirmation email 📧. Follow the instructions to log in and change your password. When your account is active, you can connect to the service. Your account may be in one of three states - the system will send you an email when your account is activated and able to access feeds.


<h3> 🚀 Apache Spark - PySpark </h3>
<hr>
To get started with this project on your local machine, you'll need to have Apache Spark installed. If you're not sure how to do that, don't worry - DataTalksClub has put together some great tutorials that cover different operating systems:

🐧 [Linux](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/linux.md)

🍎 [MacOS](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/macos.md)

🖥️ [Windows](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/windows.md)

Just pick the one that's right for you and follow the instructions.

Oh, and one more thing - we'll be using PySpark, which is the Python API for Spark. If you don't already have PySpark installed and configured, no worries - [DataTalksClub](https://github.com/DataTalksClub) has you covered there too:

🐍 [PySpark](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/pyspark.md)


Big thanks to [DataTalksClub](https://github.com/DataTalksClub) for creating these helpful tutorials! 👏

<h3> 🐍 Python Packages </h3>
<hr>
Make sure to run `pip install -r requirements.txt` to install all the necessary Python packages for this project.


