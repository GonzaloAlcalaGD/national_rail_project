# 💻 Local

## 🛠️ Pre requisites:



### 🚀 Apache Spark - PySpark

To get started with this project on your local machine, you'll need to have Apache Spark installed. If you're not sure how to do that, don't worry - DataTalksClub has put together some great tutorials that cover different operating systems:

- 🐧 [Linux](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/linux.md)
- 🍎 [MacOS](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/macos.md)
- 🖥️ [Windows](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/windows.md)

Just pick the one that's right for you and follow the instructions.

Oh, and one more thing - we'll be using PySpark, which is the Python API for Spark. If you don't already have PySpark installed and configured, no worries - [DataTalksClub](https://github.com/DataTalksClub) has you covered there too:

- 🐍 [PySpark](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/pyspark.md)

Big thanks to [DataTalksClub](https://github.com/DataTalksClub) for creating these helpful tutorials! 👏

### 🐍 Python Packages

Make sure to run the following in your terminal

```bash
pip install -r requirements.txt
```

To install all the necessary Python packages for this project.

# Usage
To run this project locally, follow the steps below:

1. Clone the repository and navigate to the project directory

2. Make sure you have all the necessary pre-requisites installed, as described in the Pre-requisites section of this README.
3. Run the following command to start the message producer:

Once you have these dependencies installed, you can clone this repository to your local machine and navigate to the project directory. From there, you can run the following command to start the message consumer:

